{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.util import ngrams\n",
    "\n",
    "# Part a. Read the data from a file\n",
    "with open('nlp_input.txt') as data:\n",
    "    text = data.read().strip()\n",
    "\n",
    "# For proper creation of sentence tokens, some text needs to be replaced. In particular ?? and (?) are used\n",
    "# which causes the sentence tokenizer to break up the sentence incorrectly.\n",
    "text = text.replace('??', 'qq')\n",
    "text = text.replace('(?)', '(q)')\n",
    "\n",
    "# Periods were added after titles to break them apart in sentence tokens. Also fixed some typos.\n",
    "text = text.replace('Setosa.io)', 'Setosa.io).')\n",
    "text = text.replace('Equation for least ordinary squares', 'Equation for least ordinary squares.')\n",
    "text = text.replace('These are known as L1 regularization(Lasso regression) and L2 regularization(ridge regression).',\n",
    "                    'These are known as L1 regularization(Lasso regression) and L2 regularization(ridge regression). ')\n",
    "text = text.replace('L2 regularization penalty term', 'L2 regularization penalty term.')\n",
    "text = text.replace('n(', 'n (')\n",
    "text = text.replace('L1 regularization penalty term', 'L1 regularization penalty term.')\n",
    "text = text.replace('significantly higher weight than the rest', 'significantly higher weight than the rest.')\n",
    "text = text.replace('Performing Lasso regression', 'Performing Lasso regression.')\n",
    "text = text.replace('Performing Elastic Net regression', 'Performing Elastic Net regression.')\n",
    "text = text.replace('1 denotes lasso)', '1 denotes lasso).')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression\n",
      "analysis\n",
      "is\n",
      "a\n",
      "statistical\n",
      "technique\n",
      "that\n",
      "models\n",
      "and\n",
      "approximates\n",
      "the\n",
      "relationship\n",
      "between\n",
      "a\n",
      "dependent\n",
      "and\n",
      "one\n",
      "or\n",
      "more\n",
      "independent\n",
      "variables\n",
      "This\n",
      "article\n",
      "will\n",
      "quickly\n",
      "introduce\n",
      "three\n",
      "commonly\n",
      "used\n",
      "regression\n",
      "models\n",
      "using\n",
      "R\n",
      "and\n",
      "the\n",
      "Boston\n",
      "housing\n",
      "data-set\n",
      "Ridge\n",
      "Lasso\n",
      "and\n",
      "Elastic\n",
      "Net\n",
      "First\n",
      "we\n",
      "need\n",
      "to\n",
      "understand\n",
      "the\n",
      "basics\n",
      "of\n",
      "regression\n",
      "and\n",
      "what\n",
      "parameters\n",
      "of\n",
      "the\n",
      "equation\n",
      "are\n",
      "changed\n",
      "when\n",
      "using\n",
      "a\n",
      "specific\n",
      "model\n",
      "Simple\n",
      "linear\n",
      "regression\n",
      "also\n",
      "known\n",
      "as\n",
      "ordinary\n",
      "least\n",
      "squares\n",
      "OLS\n",
      "attempts\n",
      "to\n",
      "minimize\n",
      "the\n",
      "sum\n",
      "of\n",
      "error\n",
      "squared\n",
      "The\n",
      "error\n",
      "in\n",
      "this\n",
      "case\n",
      "is\n",
      "the\n",
      "difference\n",
      "between\n",
      "the\n",
      "actual\n",
      "data\n",
      "point\n",
      "and\n",
      "its\n",
      "predicted\n",
      "value\n",
      "Visualization\n",
      "of\n",
      "the\n",
      "squared\n",
      "error\n",
      "from\n",
      "Setosa.io\n",
      "The\n",
      "equation\n",
      "for\n",
      "this\n",
      "model\n",
      "is\n",
      "referred\n",
      "to\n",
      "as\n",
      "the\n",
      "cost\n",
      "function\n",
      "and\n",
      "is\n",
      "a\n",
      "way\n",
      "to\n",
      "find\n",
      "the\n",
      "optimal\n",
      "error\n",
      "by\n",
      "minimizing\n",
      "and\n",
      "measuring\n",
      "it\n",
      "The\n",
      "gradient\n",
      "descent\n",
      "algorithm\n",
      "is\n",
      "used\n",
      "to\n",
      "find\n",
      "the\n",
      "optimal\n",
      "cost\n",
      "function\n",
      "by\n",
      "going\n",
      "over\n",
      "a\n",
      "number\n",
      "of\n",
      "iterations\n",
      "But\n",
      "the\n",
      "data\n",
      "we\n",
      "need\n",
      "to\n",
      "define\n",
      "and\n",
      "analyze\n",
      "is\n",
      "not\n",
      "always\n",
      "so\n",
      "easy\n",
      "to\n",
      "characterize\n",
      "with\n",
      "the\n",
      "base\n",
      "OLS\n",
      "model\n",
      "Equation\n",
      "for\n",
      "least\n",
      "ordinary\n",
      "squares\n",
      "One\n",
      "situation\n",
      "is\n",
      "the\n",
      "data\n",
      "showing\n",
      "multi-collinearity\n",
      "this\n",
      "is\n",
      "when\n",
      "predictor\n",
      "variables\n",
      "are\n",
      "correlated\n",
      "to\n",
      "each\n",
      "other\n",
      "and\n",
      "to\n",
      "the\n",
      "response\n",
      "variable\n",
      "To\n",
      "picture\n",
      "this\n",
      "let\n",
      "’\n",
      "s\n",
      "say\n",
      "we\n",
      "’\n",
      "re\n",
      "doing\n",
      "a\n",
      "study\n",
      "that\n",
      "looks\n",
      "at\n",
      "a\n",
      "response\n",
      "variable\n",
      "—\n",
      "patient\n",
      "weight\n",
      "and\n",
      "our\n",
      "predictor\n",
      "variables\n",
      "would\n",
      "be\n",
      "height\n",
      "sex\n",
      "and\n",
      "diet\n",
      "The\n",
      "problem\n",
      "here\n",
      "is\n",
      "that\n",
      "height\n",
      "and\n",
      "sex\n",
      "are\n",
      "also\n",
      "correlated\n",
      "and\n",
      "can\n",
      "inflate\n",
      "the\n",
      "standard\n",
      "error\n",
      "of\n",
      "their\n",
      "coefficients\n",
      "which\n",
      "may\n",
      "make\n",
      "them\n",
      "seem\n",
      "statistically\n",
      "insignificant\n",
      "To\n",
      "produce\n",
      "a\n",
      "more\n",
      "accurate\n",
      "model\n",
      "of\n",
      "complex\n",
      "data\n",
      "we\n",
      "can\n",
      "add\n",
      "a\n",
      "penalty\n",
      "term\n",
      "to\n",
      "the\n",
      "OLS\n",
      "equation\n",
      "A\n",
      "penalty\n",
      "adds\n",
      "a\n",
      "bias\n",
      "towards\n",
      "certain\n",
      "values\n",
      "These\n",
      "are\n",
      "known\n",
      "as\n",
      "L1\n",
      "regularization\n",
      "Lasso\n",
      "regression\n",
      "and\n",
      "L2\n",
      "regularization\n",
      "ridge\n",
      "regression\n",
      "The\n",
      "best\n",
      "model\n",
      "we\n",
      "can\n",
      "hope\n",
      "to\n",
      "come\n",
      "up\n",
      "with\n",
      "minimizes\n",
      "both\n",
      "the\n",
      "bias\n",
      "and\n",
      "the\n",
      "variance\n",
      "Ridge\n",
      "regression\n",
      "uses\n",
      "L2\n",
      "regularization\n",
      "which\n",
      "adds\n",
      "the\n",
      "following\n",
      "penalty\n",
      "term\n",
      "to\n",
      "the\n",
      "OLS\n",
      "equation\n",
      "L2\n",
      "regularization\n",
      "penalty\n",
      "term\n",
      "The\n",
      "L2\n",
      "term\n",
      "is\n",
      "equal\n",
      "to\n",
      "the\n",
      "square\n",
      "of\n",
      "the\n",
      "magnitude\n",
      "of\n",
      "the\n",
      "coefficients\n",
      "In\n",
      "this\n",
      "case\n",
      "if\n",
      "lambda\n",
      "q\n",
      "is\n",
      "zero\n",
      "then\n",
      "the\n",
      "equation\n",
      "is\n",
      "the\n",
      "basic\n",
      "OLS\n",
      "but\n",
      "if\n",
      "it\n",
      "is\n",
      "greater\n",
      "than\n",
      "zero\n",
      "then\n",
      "we\n",
      "add\n",
      "a\n",
      "constraint\n",
      "to\n",
      "the\n",
      "coefficients\n",
      "This\n",
      "constraint\n",
      "results\n",
      "in\n",
      "minimized\n",
      "coefficients\n",
      "aka\n",
      "shrinkage\n",
      "that\n",
      "trend\n",
      "towards\n",
      "zero\n",
      "the\n",
      "larger\n",
      "the\n",
      "value\n",
      "of\n",
      "lambda\n",
      "Shrinking\n",
      "the\n",
      "coefficients\n",
      "leads\n",
      "to\n",
      "a\n",
      "lower\n",
      "variance\n",
      "and\n",
      "in\n",
      "turn\n",
      "a\n",
      "lower\n",
      "error\n",
      "value\n",
      "Therefore\n",
      "Ridge\n",
      "regression\n",
      "decreases\n",
      "the\n",
      "complexity\n",
      "of\n",
      "a\n",
      "model\n",
      "but\n",
      "does\n",
      "not\n",
      "reduce\n",
      "the\n",
      "number\n",
      "of\n",
      "variables\n",
      "it\n",
      "rather\n",
      "just\n",
      "shrinks\n",
      "their\n",
      "effect\n",
      "Lasso\n",
      "regression\n",
      "Lasso\n",
      "regression\n",
      "uses\n",
      "the\n",
      "L1\n",
      "penalty\n",
      "term\n",
      "and\n",
      "stands\n",
      "for\n",
      "Least\n",
      "Absolute\n",
      "Shrinkage\n",
      "and\n",
      "Selection\n",
      "Operator\n",
      "The\n",
      "penalty\n",
      "applied\n",
      "for\n",
      "L2\n",
      "is\n",
      "equal\n",
      "to\n",
      "the\n",
      "absolute\n",
      "value\n",
      "of\n",
      "the\n",
      "magnitude\n",
      "of\n",
      "the\n",
      "coefficients\n",
      "L1\n",
      "regularization\n",
      "penalty\n",
      "term\n",
      "Similar\n",
      "to\n",
      "ridge\n",
      "regression\n",
      "a\n",
      "lambda\n",
      "value\n",
      "of\n",
      "zero\n",
      "spits\n",
      "out\n",
      "the\n",
      "basic\n",
      "OLS\n",
      "equation\n",
      "however\n",
      "given\n",
      "a\n",
      "suitable\n",
      "lambda\n",
      "value\n",
      "lasso\n",
      "regression\n",
      "can\n",
      "drive\n",
      "some\n",
      "coefficients\n",
      "to\n",
      "zero\n",
      "The\n",
      "larger\n",
      "the\n",
      "value\n",
      "of\n",
      "lambda\n",
      "the\n",
      "more\n",
      "features\n",
      "are\n",
      "shrunk\n",
      "to\n",
      "zero\n",
      "This\n",
      "can\n",
      "eliminate\n",
      "some\n",
      "features\n",
      "entirely\n",
      "and\n",
      "give\n",
      "us\n",
      "a\n",
      "subset\n",
      "of\n",
      "predictors\n",
      "that\n",
      "helps\n",
      "mitigate\n",
      "multi-collinearity\n",
      "and\n",
      "model\n",
      "complexity\n",
      "Predictors\n",
      "not\n",
      "shrunk\n",
      "towards\n",
      "zero\n",
      "signify\n",
      "that\n",
      "they\n",
      "are\n",
      "important\n",
      "and\n",
      "thus\n",
      "L1\n",
      "regularization\n",
      "allows\n",
      "for\n",
      "feature\n",
      "selection\n",
      "sparse\n",
      "selection\n",
      "A\n",
      "third\n",
      "commonly\n",
      "used\n",
      "model\n",
      "of\n",
      "regression\n",
      "is\n",
      "the\n",
      "Elastic\n",
      "Net\n",
      "which\n",
      "incorporates\n",
      "penalties\n",
      "from\n",
      "both\n",
      "L1\n",
      "and\n",
      "L2\n",
      "regularization\n",
      "In\n",
      "addition\n",
      "to\n",
      "setting\n",
      "and\n",
      "choosing\n",
      "a\n",
      "lambda\n",
      "value\n",
      "elastic\n",
      "net\n",
      "also\n",
      "allows\n",
      "us\n",
      "to\n",
      "tune\n",
      "the\n",
      "alpha\n",
      "parameter\n",
      "where\n",
      "qq\n",
      "0\n",
      "corresponds\n",
      "to\n",
      "ridge\n",
      "and\n",
      "qq\n",
      "1\n",
      "to\n",
      "lasso\n",
      "Simply\n",
      "put\n",
      "if\n",
      "you\n",
      "plug\n",
      "in\n",
      "0\n",
      "for\n",
      "alpha\n",
      "the\n",
      "penalty\n",
      "function\n",
      "reduces\n",
      "to\n",
      "the\n",
      "L1\n",
      "ridge\n",
      "term\n",
      "and\n",
      "if\n",
      "we\n",
      "set\n",
      "alpha\n",
      "to\n",
      "1\n",
      "we\n",
      "get\n",
      "the\n",
      "L2\n",
      "lasso\n",
      "term\n",
      "Therefore\n",
      "we\n",
      "can\n",
      "choose\n",
      "an\n",
      "alpha\n",
      "value\n",
      "between\n",
      "0\n",
      "and\n",
      "1\n",
      "to\n",
      "optimize\n",
      "the\n",
      "elastic\n",
      "net\n",
      "Effectively\n",
      "this\n",
      "will\n",
      "shrink\n",
      "some\n",
      "coefficients\n",
      "and\n",
      "set\n",
      "some\n",
      "to\n",
      "0\n",
      "for\n",
      "sparse\n",
      "selection\n",
      "As\n",
      "we\n",
      "mentioned\n",
      "in\n",
      "the\n",
      "previous\n",
      "sections\n",
      "lambda\n",
      "values\n",
      "have\n",
      "a\n",
      "large\n",
      "effect\n",
      "on\n",
      "coefficients\n",
      "so\n",
      "now\n",
      "we\n",
      "will\n",
      "compute\n",
      "and\n",
      "chose\n",
      "a\n",
      "suitable\n",
      "one\n",
      "Here\n",
      "we\n",
      "perform\n",
      "a\n",
      "cross\n",
      "validation\n",
      "and\n",
      "take\n",
      "a\n",
      "peek\n",
      "at\n",
      "the\n",
      "lambda\n",
      "value\n",
      "corresponding\n",
      "to\n",
      "the\n",
      "lowest\n",
      "prediction\n",
      "error\n",
      "before\n",
      "fitting\n",
      "the\n",
      "data\n",
      "to\n",
      "the\n",
      "model\n",
      "and\n",
      "viewing\n",
      "the\n",
      "coefficients\n",
      "We\n",
      "can\n",
      "see\n",
      "here\n",
      "that\n",
      "certain\n",
      "coefficients\n",
      "have\n",
      "been\n",
      "pushed\n",
      "towards\n",
      "zero\n",
      "and\n",
      "minimized\n",
      "while\n",
      "RM\n",
      "number\n",
      "of\n",
      "rooms\n",
      "has\n",
      "a\n",
      "significantly\n",
      "higher\n",
      "weight\n",
      "than\n",
      "the\n",
      "rest\n",
      "Performing\n",
      "Lasso\n",
      "regression\n",
      "The\n",
      "steps\n",
      "will\n",
      "be\n",
      "identical\n",
      "to\n",
      "what\n",
      "we\n",
      "have\n",
      "done\n",
      "for\n",
      "ridge\n",
      "regression\n",
      "The\n",
      "value\n",
      "of\n",
      "alpha\n",
      "is\n",
      "the\n",
      "only\n",
      "change\n",
      "here\n",
      "remember\n",
      "qq\n",
      "1\n",
      "denotes\n",
      "lasso\n",
      "Performing\n",
      "Elastic\n",
      "Net\n",
      "regression\n",
      "Performing\n",
      "Elastic\n",
      "Net\n",
      "requires\n",
      "us\n",
      "to\n",
      "tune\n",
      "parameters\n",
      "to\n",
      "identify\n",
      "the\n",
      "best\n",
      "alpha\n",
      "and\n",
      "lambda\n",
      "values\n",
      "and\n",
      "for\n",
      "this\n",
      "we\n",
      "need\n",
      "to\n",
      "use\n",
      "the\n",
      "caret\n",
      "package\n",
      "We\n",
      "will\n",
      "tune\n",
      "the\n",
      "model\n",
      "by\n",
      "iterating\n",
      "over\n",
      "a\n",
      "number\n",
      "of\n",
      "alpha\n",
      "and\n",
      "lambda\n",
      "pairs\n",
      "and\n",
      "we\n",
      "can\n",
      "see\n",
      "which\n",
      "pair\n",
      "has\n",
      "the\n",
      "lowest\n",
      "associated\n",
      "error\n",
      "We\n",
      "can\n",
      "see\n",
      "that\n",
      "the\n",
      "R\n",
      "mean-squared\n",
      "values\n",
      "using\n",
      "all\n",
      "three\n",
      "models\n",
      "were\n",
      "very\n",
      "close\n",
      "to\n",
      "each\n",
      "other\n",
      "but\n",
      "both\n",
      "did\n",
      "marginally\n",
      "perform\n",
      "better\n",
      "than\n",
      "ridge\n",
      "regression\n",
      "Lasso\n",
      "having\n",
      "done\n",
      "best\n",
      "Lasso\n",
      "regression\n",
      "also\n",
      "showed\n",
      "the\n",
      "highest\n",
      "R²\n",
      "value\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from string import punctuation\n",
    "stoplist = set(list(punctuation))\n",
    "\n",
    "# Punctuation was not wanted to be part of the tokens created\n",
    "wtokens = [token for token in nltk.word_tokenize(text) if token.lower() not in stoplist]\n",
    "\n",
    "for i in wtokens:\n",
    "    print(i)\n",
    "\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Regression', 'analysis', 'is')\n",
      "('analysis', 'is', 'a')\n",
      "('is', 'a', 'statistical')\n",
      "('a', 'statistical', 'technique')\n",
      "('statistical', 'technique', 'that')\n",
      "('technique', 'that', 'models')\n",
      "('that', 'models', 'and')\n",
      "('models', 'and', 'approximates')\n",
      "('and', 'approximates', 'the')\n",
      "('approximates', 'the', 'relationship')\n",
      "('the', 'relationship', 'between')\n",
      "('relationship', 'between', 'a')\n",
      "('between', 'a', 'dependent')\n",
      "('a', 'dependent', 'and')\n",
      "('dependent', 'and', 'one')\n",
      "('and', 'one', 'or')\n",
      "('one', 'or', 'more')\n",
      "('or', 'more', 'independent')\n",
      "('more', 'independent', 'variables')\n",
      "('independent', 'variables', 'This')\n",
      "('variables', 'This', 'article')\n",
      "('This', 'article', 'will')\n",
      "('article', 'will', 'quickly')\n",
      "('will', 'quickly', 'introduce')\n",
      "('quickly', 'introduce', 'three')\n",
      "('introduce', 'three', 'commonly')\n",
      "('three', 'commonly', 'used')\n",
      "('commonly', 'used', 'regression')\n",
      "('used', 'regression', 'models')\n",
      "('regression', 'models', 'using')\n",
      "('models', 'using', 'R')\n",
      "('using', 'R', 'and')\n",
      "('R', 'and', 'the')\n",
      "('and', 'the', 'Boston')\n",
      "('the', 'Boston', 'housing')\n",
      "('Boston', 'housing', 'data-set')\n",
      "('housing', 'data-set', 'Ridge')\n",
      "('data-set', 'Ridge', 'Lasso')\n",
      "('Ridge', 'Lasso', 'and')\n",
      "('Lasso', 'and', 'Elastic')\n",
      "('and', 'Elastic', 'Net')\n",
      "('Elastic', 'Net', 'First')\n",
      "('Net', 'First', 'we')\n",
      "('First', 'we', 'need')\n",
      "('we', 'need', 'to')\n",
      "('need', 'to', 'understand')\n",
      "('to', 'understand', 'the')\n",
      "('understand', 'the', 'basics')\n",
      "('the', 'basics', 'of')\n",
      "('basics', 'of', 'regression')\n",
      "('of', 'regression', 'and')\n",
      "('regression', 'and', 'what')\n",
      "('and', 'what', 'parameters')\n",
      "('what', 'parameters', 'of')\n",
      "('parameters', 'of', 'the')\n",
      "('of', 'the', 'equation')\n",
      "('the', 'equation', 'are')\n",
      "('equation', 'are', 'changed')\n",
      "('are', 'changed', 'when')\n",
      "('changed', 'when', 'using')\n",
      "('when', 'using', 'a')\n",
      "('using', 'a', 'specific')\n",
      "('a', 'specific', 'model')\n",
      "('specific', 'model', 'Simple')\n",
      "('model', 'Simple', 'linear')\n",
      "('Simple', 'linear', 'regression')\n",
      "('linear', 'regression', 'also')\n",
      "('regression', 'also', 'known')\n",
      "('also', 'known', 'as')\n",
      "('known', 'as', 'ordinary')\n",
      "('as', 'ordinary', 'least')\n",
      "('ordinary', 'least', 'squares')\n",
      "('least', 'squares', 'OLS')\n",
      "('squares', 'OLS', 'attempts')\n",
      "('OLS', 'attempts', 'to')\n",
      "('attempts', 'to', 'minimize')\n",
      "('to', 'minimize', 'the')\n",
      "('minimize', 'the', 'sum')\n",
      "('the', 'sum', 'of')\n",
      "('sum', 'of', 'error')\n",
      "('of', 'error', 'squared')\n",
      "('error', 'squared', 'The')\n",
      "('squared', 'The', 'error')\n",
      "('The', 'error', 'in')\n",
      "('error', 'in', 'this')\n",
      "('in', 'this', 'case')\n",
      "('this', 'case', 'is')\n",
      "('case', 'is', 'the')\n",
      "('is', 'the', 'difference')\n",
      "('the', 'difference', 'between')\n",
      "('difference', 'between', 'the')\n",
      "('between', 'the', 'actual')\n",
      "('the', 'actual', 'data')\n",
      "('actual', 'data', 'point')\n",
      "('data', 'point', 'and')\n",
      "('point', 'and', 'its')\n",
      "('and', 'its', 'predicted')\n",
      "('its', 'predicted', 'value')\n",
      "('predicted', 'value', 'Visualization')\n",
      "('value', 'Visualization', 'of')\n",
      "('Visualization', 'of', 'the')\n",
      "('of', 'the', 'squared')\n",
      "('the', 'squared', 'error')\n",
      "('squared', 'error', 'from')\n",
      "('error', 'from', 'Setosa.io')\n",
      "('from', 'Setosa.io', 'The')\n",
      "('Setosa.io', 'The', 'equation')\n",
      "('The', 'equation', 'for')\n",
      "('equation', 'for', 'this')\n",
      "('for', 'this', 'model')\n",
      "('this', 'model', 'is')\n",
      "('model', 'is', 'referred')\n",
      "('is', 'referred', 'to')\n",
      "('referred', 'to', 'as')\n",
      "('to', 'as', 'the')\n",
      "('as', 'the', 'cost')\n",
      "('the', 'cost', 'function')\n",
      "('cost', 'function', 'and')\n",
      "('function', 'and', 'is')\n",
      "('and', 'is', 'a')\n",
      "('is', 'a', 'way')\n",
      "('a', 'way', 'to')\n",
      "('way', 'to', 'find')\n",
      "('to', 'find', 'the')\n",
      "('find', 'the', 'optimal')\n",
      "('the', 'optimal', 'error')\n",
      "('optimal', 'error', 'by')\n",
      "('error', 'by', 'minimizing')\n",
      "('by', 'minimizing', 'and')\n",
      "('minimizing', 'and', 'measuring')\n",
      "('and', 'measuring', 'it')\n",
      "('measuring', 'it', 'The')\n",
      "('it', 'The', 'gradient')\n",
      "('The', 'gradient', 'descent')\n",
      "('gradient', 'descent', 'algorithm')\n",
      "('descent', 'algorithm', 'is')\n",
      "('algorithm', 'is', 'used')\n",
      "('is', 'used', 'to')\n",
      "('used', 'to', 'find')\n",
      "('to', 'find', 'the')\n",
      "('find', 'the', 'optimal')\n",
      "('the', 'optimal', 'cost')\n",
      "('optimal', 'cost', 'function')\n",
      "('cost', 'function', 'by')\n",
      "('function', 'by', 'going')\n",
      "('by', 'going', 'over')\n",
      "('going', 'over', 'a')\n",
      "('over', 'a', 'number')\n",
      "('a', 'number', 'of')\n",
      "('number', 'of', 'iterations')\n",
      "('of', 'iterations', 'But')\n",
      "('iterations', 'But', 'the')\n",
      "('But', 'the', 'data')\n",
      "('the', 'data', 'we')\n",
      "('data', 'we', 'need')\n",
      "('we', 'need', 'to')\n",
      "('need', 'to', 'define')\n",
      "('to', 'define', 'and')\n",
      "('define', 'and', 'analyze')\n",
      "('and', 'analyze', 'is')\n",
      "('analyze', 'is', 'not')\n",
      "('is', 'not', 'always')\n",
      "('not', 'always', 'so')\n",
      "('always', 'so', 'easy')\n",
      "('so', 'easy', 'to')\n",
      "('easy', 'to', 'characterize')\n",
      "('to', 'characterize', 'with')\n",
      "('characterize', 'with', 'the')\n",
      "('with', 'the', 'base')\n",
      "('the', 'base', 'OLS')\n",
      "('base', 'OLS', 'model')\n",
      "('OLS', 'model', 'Equation')\n",
      "('model', 'Equation', 'for')\n",
      "('Equation', 'for', 'least')\n",
      "('for', 'least', 'ordinary')\n",
      "('least', 'ordinary', 'squares')\n",
      "('ordinary', 'squares', 'One')\n",
      "('squares', 'One', 'situation')\n",
      "('One', 'situation', 'is')\n",
      "('situation', 'is', 'the')\n",
      "('is', 'the', 'data')\n",
      "('the', 'data', 'showing')\n",
      "('data', 'showing', 'multi-collinearity')\n",
      "('showing', 'multi-collinearity', 'this')\n",
      "('multi-collinearity', 'this', 'is')\n",
      "('this', 'is', 'when')\n",
      "('is', 'when', 'predictor')\n",
      "('when', 'predictor', 'variables')\n",
      "('predictor', 'variables', 'are')\n",
      "('variables', 'are', 'correlated')\n",
      "('are', 'correlated', 'to')\n",
      "('correlated', 'to', 'each')\n",
      "('to', 'each', 'other')\n",
      "('each', 'other', 'and')\n",
      "('other', 'and', 'to')\n",
      "('and', 'to', 'the')\n",
      "('to', 'the', 'response')\n",
      "('the', 'response', 'variable')\n",
      "('response', 'variable', 'To')\n",
      "('variable', 'To', 'picture')\n",
      "('To', 'picture', 'this')\n",
      "('picture', 'this', 'let')\n",
      "('this', 'let', '’')\n",
      "('let', '’', 's')\n",
      "('’', 's', 'say')\n",
      "('s', 'say', 'we')\n",
      "('say', 'we', '’')\n",
      "('we', '’', 're')\n",
      "('’', 're', 'doing')\n",
      "('re', 'doing', 'a')\n",
      "('doing', 'a', 'study')\n",
      "('a', 'study', 'that')\n",
      "('study', 'that', 'looks')\n",
      "('that', 'looks', 'at')\n",
      "('looks', 'at', 'a')\n",
      "('at', 'a', 'response')\n",
      "('a', 'response', 'variable')\n",
      "('response', 'variable', '—')\n",
      "('variable', '—', 'patient')\n",
      "('—', 'patient', 'weight')\n",
      "('patient', 'weight', 'and')\n",
      "('weight', 'and', 'our')\n",
      "('and', 'our', 'predictor')\n",
      "('our', 'predictor', 'variables')\n",
      "('predictor', 'variables', 'would')\n",
      "('variables', 'would', 'be')\n",
      "('would', 'be', 'height')\n",
      "('be', 'height', 'sex')\n",
      "('height', 'sex', 'and')\n",
      "('sex', 'and', 'diet')\n",
      "('and', 'diet', 'The')\n",
      "('diet', 'The', 'problem')\n",
      "('The', 'problem', 'here')\n",
      "('problem', 'here', 'is')\n",
      "('here', 'is', 'that')\n",
      "('is', 'that', 'height')\n",
      "('that', 'height', 'and')\n",
      "('height', 'and', 'sex')\n",
      "('and', 'sex', 'are')\n",
      "('sex', 'are', 'also')\n",
      "('are', 'also', 'correlated')\n",
      "('also', 'correlated', 'and')\n",
      "('correlated', 'and', 'can')\n",
      "('and', 'can', 'inflate')\n",
      "('can', 'inflate', 'the')\n",
      "('inflate', 'the', 'standard')\n",
      "('the', 'standard', 'error')\n",
      "('standard', 'error', 'of')\n",
      "('error', 'of', 'their')\n",
      "('of', 'their', 'coefficients')\n",
      "('their', 'coefficients', 'which')\n",
      "('coefficients', 'which', 'may')\n",
      "('which', 'may', 'make')\n",
      "('may', 'make', 'them')\n",
      "('make', 'them', 'seem')\n",
      "('them', 'seem', 'statistically')\n",
      "('seem', 'statistically', 'insignificant')\n",
      "('statistically', 'insignificant', 'To')\n",
      "('insignificant', 'To', 'produce')\n",
      "('To', 'produce', 'a')\n",
      "('produce', 'a', 'more')\n",
      "('a', 'more', 'accurate')\n",
      "('more', 'accurate', 'model')\n",
      "('accurate', 'model', 'of')\n",
      "('model', 'of', 'complex')\n",
      "('of', 'complex', 'data')\n",
      "('complex', 'data', 'we')\n",
      "('data', 'we', 'can')\n",
      "('we', 'can', 'add')\n",
      "('can', 'add', 'a')\n",
      "('add', 'a', 'penalty')\n",
      "('a', 'penalty', 'term')\n",
      "('penalty', 'term', 'to')\n",
      "('term', 'to', 'the')\n",
      "('to', 'the', 'OLS')\n",
      "('the', 'OLS', 'equation')\n",
      "('OLS', 'equation', 'A')\n",
      "('equation', 'A', 'penalty')\n",
      "('A', 'penalty', 'adds')\n",
      "('penalty', 'adds', 'a')\n",
      "('adds', 'a', 'bias')\n",
      "('a', 'bias', 'towards')\n",
      "('bias', 'towards', 'certain')\n",
      "('towards', 'certain', 'values')\n",
      "('certain', 'values', 'These')\n",
      "('values', 'These', 'are')\n",
      "('These', 'are', 'known')\n",
      "('are', 'known', 'as')\n",
      "('known', 'as', 'L1')\n",
      "('as', 'L1', 'regularization')\n",
      "('L1', 'regularization', 'Lasso')\n",
      "('regularization', 'Lasso', 'regression')\n",
      "('Lasso', 'regression', 'and')\n",
      "('regression', 'and', 'L2')\n",
      "('and', 'L2', 'regularization')\n",
      "('L2', 'regularization', 'ridge')\n",
      "('regularization', 'ridge', 'regression')\n",
      "('ridge', 'regression', 'The')\n",
      "('regression', 'The', 'best')\n",
      "('The', 'best', 'model')\n",
      "('best', 'model', 'we')\n",
      "('model', 'we', 'can')\n",
      "('we', 'can', 'hope')\n",
      "('can', 'hope', 'to')\n",
      "('hope', 'to', 'come')\n",
      "('to', 'come', 'up')\n",
      "('come', 'up', 'with')\n",
      "('up', 'with', 'minimizes')\n",
      "('with', 'minimizes', 'both')\n",
      "('minimizes', 'both', 'the')\n",
      "('both', 'the', 'bias')\n",
      "('the', 'bias', 'and')\n",
      "('bias', 'and', 'the')\n",
      "('and', 'the', 'variance')\n",
      "('the', 'variance', 'Ridge')\n",
      "('variance', 'Ridge', 'regression')\n",
      "('Ridge', 'regression', 'uses')\n",
      "('regression', 'uses', 'L2')\n",
      "('uses', 'L2', 'regularization')\n",
      "('L2', 'regularization', 'which')\n",
      "('regularization', 'which', 'adds')\n",
      "('which', 'adds', 'the')\n",
      "('adds', 'the', 'following')\n",
      "('the', 'following', 'penalty')\n",
      "('following', 'penalty', 'term')\n",
      "('penalty', 'term', 'to')\n",
      "('term', 'to', 'the')\n",
      "('to', 'the', 'OLS')\n",
      "('the', 'OLS', 'equation')\n",
      "('OLS', 'equation', 'L2')\n",
      "('equation', 'L2', 'regularization')\n",
      "('L2', 'regularization', 'penalty')\n",
      "('regularization', 'penalty', 'term')\n",
      "('penalty', 'term', 'The')\n",
      "('term', 'The', 'L2')\n",
      "('The', 'L2', 'term')\n",
      "('L2', 'term', 'is')\n",
      "('term', 'is', 'equal')\n",
      "('is', 'equal', 'to')\n",
      "('equal', 'to', 'the')\n",
      "('to', 'the', 'square')\n",
      "('the', 'square', 'of')\n",
      "('square', 'of', 'the')\n",
      "('of', 'the', 'magnitude')\n",
      "('the', 'magnitude', 'of')\n",
      "('magnitude', 'of', 'the')\n",
      "('of', 'the', 'coefficients')\n",
      "('the', 'coefficients', 'In')\n",
      "('coefficients', 'In', 'this')\n",
      "('In', 'this', 'case')\n",
      "('this', 'case', 'if')\n",
      "('case', 'if', 'lambda')\n",
      "('if', 'lambda', 'q')\n",
      "('lambda', 'q', 'is')\n",
      "('q', 'is', 'zero')\n",
      "('is', 'zero', 'then')\n",
      "('zero', 'then', 'the')\n",
      "('then', 'the', 'equation')\n",
      "('the', 'equation', 'is')\n",
      "('equation', 'is', 'the')\n",
      "('is', 'the', 'basic')\n",
      "('the', 'basic', 'OLS')\n",
      "('basic', 'OLS', 'but')\n",
      "('OLS', 'but', 'if')\n",
      "('but', 'if', 'it')\n",
      "('if', 'it', 'is')\n",
      "('it', 'is', 'greater')\n",
      "('is', 'greater', 'than')\n",
      "('greater', 'than', 'zero')\n",
      "('than', 'zero', 'then')\n",
      "('zero', 'then', 'we')\n",
      "('then', 'we', 'add')\n",
      "('we', 'add', 'a')\n",
      "('add', 'a', 'constraint')\n",
      "('a', 'constraint', 'to')\n",
      "('constraint', 'to', 'the')\n",
      "('to', 'the', 'coefficients')\n",
      "('the', 'coefficients', 'This')\n",
      "('coefficients', 'This', 'constraint')\n",
      "('This', 'constraint', 'results')\n",
      "('constraint', 'results', 'in')\n",
      "('results', 'in', 'minimized')\n",
      "('in', 'minimized', 'coefficients')\n",
      "('minimized', 'coefficients', 'aka')\n",
      "('coefficients', 'aka', 'shrinkage')\n",
      "('aka', 'shrinkage', 'that')\n",
      "('shrinkage', 'that', 'trend')\n",
      "('that', 'trend', 'towards')\n",
      "('trend', 'towards', 'zero')\n",
      "('towards', 'zero', 'the')\n",
      "('zero', 'the', 'larger')\n",
      "('the', 'larger', 'the')\n",
      "('larger', 'the', 'value')\n",
      "('the', 'value', 'of')\n",
      "('value', 'of', 'lambda')\n",
      "('of', 'lambda', 'Shrinking')\n",
      "('lambda', 'Shrinking', 'the')\n",
      "('Shrinking', 'the', 'coefficients')\n",
      "('the', 'coefficients', 'leads')\n",
      "('coefficients', 'leads', 'to')\n",
      "('leads', 'to', 'a')\n",
      "('to', 'a', 'lower')\n",
      "('a', 'lower', 'variance')\n",
      "('lower', 'variance', 'and')\n",
      "('variance', 'and', 'in')\n",
      "('and', 'in', 'turn')\n",
      "('in', 'turn', 'a')\n",
      "('turn', 'a', 'lower')\n",
      "('a', 'lower', 'error')\n",
      "('lower', 'error', 'value')\n",
      "('error', 'value', 'Therefore')\n",
      "('value', 'Therefore', 'Ridge')\n",
      "('Therefore', 'Ridge', 'regression')\n",
      "('Ridge', 'regression', 'decreases')\n",
      "('regression', 'decreases', 'the')\n",
      "('decreases', 'the', 'complexity')\n",
      "('the', 'complexity', 'of')\n",
      "('complexity', 'of', 'a')\n",
      "('of', 'a', 'model')\n",
      "('a', 'model', 'but')\n",
      "('model', 'but', 'does')\n",
      "('but', 'does', 'not')\n",
      "('does', 'not', 'reduce')\n",
      "('not', 'reduce', 'the')\n",
      "('reduce', 'the', 'number')\n",
      "('the', 'number', 'of')\n",
      "('number', 'of', 'variables')\n",
      "('of', 'variables', 'it')\n",
      "('variables', 'it', 'rather')\n",
      "('it', 'rather', 'just')\n",
      "('rather', 'just', 'shrinks')\n",
      "('just', 'shrinks', 'their')\n",
      "('shrinks', 'their', 'effect')\n",
      "('their', 'effect', 'Lasso')\n",
      "('effect', 'Lasso', 'regression')\n",
      "('Lasso', 'regression', 'Lasso')\n",
      "('regression', 'Lasso', 'regression')\n",
      "('Lasso', 'regression', 'uses')\n",
      "('regression', 'uses', 'the')\n",
      "('uses', 'the', 'L1')\n",
      "('the', 'L1', 'penalty')\n",
      "('L1', 'penalty', 'term')\n",
      "('penalty', 'term', 'and')\n",
      "('term', 'and', 'stands')\n",
      "('and', 'stands', 'for')\n",
      "('stands', 'for', 'Least')\n",
      "('for', 'Least', 'Absolute')\n",
      "('Least', 'Absolute', 'Shrinkage')\n",
      "('Absolute', 'Shrinkage', 'and')\n",
      "('Shrinkage', 'and', 'Selection')\n",
      "('and', 'Selection', 'Operator')\n",
      "('Selection', 'Operator', 'The')\n",
      "('Operator', 'The', 'penalty')\n",
      "('The', 'penalty', 'applied')\n",
      "('penalty', 'applied', 'for')\n",
      "('applied', 'for', 'L2')\n",
      "('for', 'L2', 'is')\n",
      "('L2', 'is', 'equal')\n",
      "('is', 'equal', 'to')\n",
      "('equal', 'to', 'the')\n",
      "('to', 'the', 'absolute')\n",
      "('the', 'absolute', 'value')\n",
      "('absolute', 'value', 'of')\n",
      "('value', 'of', 'the')\n",
      "('of', 'the', 'magnitude')\n",
      "('the', 'magnitude', 'of')\n",
      "('magnitude', 'of', 'the')\n",
      "('of', 'the', 'coefficients')\n",
      "('the', 'coefficients', 'L1')\n",
      "('coefficients', 'L1', 'regularization')\n",
      "('L1', 'regularization', 'penalty')\n",
      "('regularization', 'penalty', 'term')\n",
      "('penalty', 'term', 'Similar')\n",
      "('term', 'Similar', 'to')\n",
      "('Similar', 'to', 'ridge')\n",
      "('to', 'ridge', 'regression')\n",
      "('ridge', 'regression', 'a')\n",
      "('regression', 'a', 'lambda')\n",
      "('a', 'lambda', 'value')\n",
      "('lambda', 'value', 'of')\n",
      "('value', 'of', 'zero')\n",
      "('of', 'zero', 'spits')\n",
      "('zero', 'spits', 'out')\n",
      "('spits', 'out', 'the')\n",
      "('out', 'the', 'basic')\n",
      "('the', 'basic', 'OLS')\n",
      "('basic', 'OLS', 'equation')\n",
      "('OLS', 'equation', 'however')\n",
      "('equation', 'however', 'given')\n",
      "('however', 'given', 'a')\n",
      "('given', 'a', 'suitable')\n",
      "('a', 'suitable', 'lambda')\n",
      "('suitable', 'lambda', 'value')\n",
      "('lambda', 'value', 'lasso')\n",
      "('value', 'lasso', 'regression')\n",
      "('lasso', 'regression', 'can')\n",
      "('regression', 'can', 'drive')\n",
      "('can', 'drive', 'some')\n",
      "('drive', 'some', 'coefficients')\n",
      "('some', 'coefficients', 'to')\n",
      "('coefficients', 'to', 'zero')\n",
      "('to', 'zero', 'The')\n",
      "('zero', 'The', 'larger')\n",
      "('The', 'larger', 'the')\n",
      "('larger', 'the', 'value')\n",
      "('the', 'value', 'of')\n",
      "('value', 'of', 'lambda')\n",
      "('of', 'lambda', 'the')\n",
      "('lambda', 'the', 'more')\n",
      "('the', 'more', 'features')\n",
      "('more', 'features', 'are')\n",
      "('features', 'are', 'shrunk')\n",
      "('are', 'shrunk', 'to')\n",
      "('shrunk', 'to', 'zero')\n",
      "('to', 'zero', 'This')\n",
      "('zero', 'This', 'can')\n",
      "('This', 'can', 'eliminate')\n",
      "('can', 'eliminate', 'some')\n",
      "('eliminate', 'some', 'features')\n",
      "('some', 'features', 'entirely')\n",
      "('features', 'entirely', 'and')\n",
      "('entirely', 'and', 'give')\n",
      "('and', 'give', 'us')\n",
      "('give', 'us', 'a')\n",
      "('us', 'a', 'subset')\n",
      "('a', 'subset', 'of')\n",
      "('subset', 'of', 'predictors')\n",
      "('of', 'predictors', 'that')\n",
      "('predictors', 'that', 'helps')\n",
      "('that', 'helps', 'mitigate')\n",
      "('helps', 'mitigate', 'multi-collinearity')\n",
      "('mitigate', 'multi-collinearity', 'and')\n",
      "('multi-collinearity', 'and', 'model')\n",
      "('and', 'model', 'complexity')\n",
      "('model', 'complexity', 'Predictors')\n",
      "('complexity', 'Predictors', 'not')\n",
      "('Predictors', 'not', 'shrunk')\n",
      "('not', 'shrunk', 'towards')\n",
      "('shrunk', 'towards', 'zero')\n",
      "('towards', 'zero', 'signify')\n",
      "('zero', 'signify', 'that')\n",
      "('signify', 'that', 'they')\n",
      "('that', 'they', 'are')\n",
      "('they', 'are', 'important')\n",
      "('are', 'important', 'and')\n",
      "('important', 'and', 'thus')\n",
      "('and', 'thus', 'L1')\n",
      "('thus', 'L1', 'regularization')\n",
      "('L1', 'regularization', 'allows')\n",
      "('regularization', 'allows', 'for')\n",
      "('allows', 'for', 'feature')\n",
      "('for', 'feature', 'selection')\n",
      "('feature', 'selection', 'sparse')\n",
      "('selection', 'sparse', 'selection')\n",
      "('sparse', 'selection', 'A')\n",
      "('selection', 'A', 'third')\n",
      "('A', 'third', 'commonly')\n",
      "('third', 'commonly', 'used')\n",
      "('commonly', 'used', 'model')\n",
      "('used', 'model', 'of')\n",
      "('model', 'of', 'regression')\n",
      "('of', 'regression', 'is')\n",
      "('regression', 'is', 'the')\n",
      "('is', 'the', 'Elastic')\n",
      "('the', 'Elastic', 'Net')\n",
      "('Elastic', 'Net', 'which')\n",
      "('Net', 'which', 'incorporates')\n",
      "('which', 'incorporates', 'penalties')\n",
      "('incorporates', 'penalties', 'from')\n",
      "('penalties', 'from', 'both')\n",
      "('from', 'both', 'L1')\n",
      "('both', 'L1', 'and')\n",
      "('L1', 'and', 'L2')\n",
      "('and', 'L2', 'regularization')\n",
      "('L2', 'regularization', 'In')\n",
      "('regularization', 'In', 'addition')\n",
      "('In', 'addition', 'to')\n",
      "('addition', 'to', 'setting')\n",
      "('to', 'setting', 'and')\n",
      "('setting', 'and', 'choosing')\n",
      "('and', 'choosing', 'a')\n",
      "('choosing', 'a', 'lambda')\n",
      "('a', 'lambda', 'value')\n",
      "('lambda', 'value', 'elastic')\n",
      "('value', 'elastic', 'net')\n",
      "('elastic', 'net', 'also')\n",
      "('net', 'also', 'allows')\n",
      "('also', 'allows', 'us')\n",
      "('allows', 'us', 'to')\n",
      "('us', 'to', 'tune')\n",
      "('to', 'tune', 'the')\n",
      "('tune', 'the', 'alpha')\n",
      "('the', 'alpha', 'parameter')\n",
      "('alpha', 'parameter', 'where')\n",
      "('parameter', 'where', 'qq')\n",
      "('where', 'qq', '0')\n",
      "('qq', '0', 'corresponds')\n",
      "('0', 'corresponds', 'to')\n",
      "('corresponds', 'to', 'ridge')\n",
      "('to', 'ridge', 'and')\n",
      "('ridge', 'and', 'qq')\n",
      "('and', 'qq', '1')\n",
      "('qq', '1', 'to')\n",
      "('1', 'to', 'lasso')\n",
      "('to', 'lasso', 'Simply')\n",
      "('lasso', 'Simply', 'put')\n",
      "('Simply', 'put', 'if')\n",
      "('put', 'if', 'you')\n",
      "('if', 'you', 'plug')\n",
      "('you', 'plug', 'in')\n",
      "('plug', 'in', '0')\n",
      "('in', '0', 'for')\n",
      "('0', 'for', 'alpha')\n",
      "('for', 'alpha', 'the')\n",
      "('alpha', 'the', 'penalty')\n",
      "('the', 'penalty', 'function')\n",
      "('penalty', 'function', 'reduces')\n",
      "('function', 'reduces', 'to')\n",
      "('reduces', 'to', 'the')\n",
      "('to', 'the', 'L1')\n",
      "('the', 'L1', 'ridge')\n",
      "('L1', 'ridge', 'term')\n",
      "('ridge', 'term', 'and')\n",
      "('term', 'and', 'if')\n",
      "('and', 'if', 'we')\n",
      "('if', 'we', 'set')\n",
      "('we', 'set', 'alpha')\n",
      "('set', 'alpha', 'to')\n",
      "('alpha', 'to', '1')\n",
      "('to', '1', 'we')\n",
      "('1', 'we', 'get')\n",
      "('we', 'get', 'the')\n",
      "('get', 'the', 'L2')\n",
      "('the', 'L2', 'lasso')\n",
      "('L2', 'lasso', 'term')\n",
      "('lasso', 'term', 'Therefore')\n",
      "('term', 'Therefore', 'we')\n",
      "('Therefore', 'we', 'can')\n",
      "('we', 'can', 'choose')\n",
      "('can', 'choose', 'an')\n",
      "('choose', 'an', 'alpha')\n",
      "('an', 'alpha', 'value')\n",
      "('alpha', 'value', 'between')\n",
      "('value', 'between', '0')\n",
      "('between', '0', 'and')\n",
      "('0', 'and', '1')\n",
      "('and', '1', 'to')\n",
      "('1', 'to', 'optimize')\n",
      "('to', 'optimize', 'the')\n",
      "('optimize', 'the', 'elastic')\n",
      "('the', 'elastic', 'net')\n",
      "('elastic', 'net', 'Effectively')\n",
      "('net', 'Effectively', 'this')\n",
      "('Effectively', 'this', 'will')\n",
      "('this', 'will', 'shrink')\n",
      "('will', 'shrink', 'some')\n",
      "('shrink', 'some', 'coefficients')\n",
      "('some', 'coefficients', 'and')\n",
      "('coefficients', 'and', 'set')\n",
      "('and', 'set', 'some')\n",
      "('set', 'some', 'to')\n",
      "('some', 'to', '0')\n",
      "('to', '0', 'for')\n",
      "('0', 'for', 'sparse')\n",
      "('for', 'sparse', 'selection')\n",
      "('sparse', 'selection', 'As')\n",
      "('selection', 'As', 'we')\n",
      "('As', 'we', 'mentioned')\n",
      "('we', 'mentioned', 'in')\n",
      "('mentioned', 'in', 'the')\n",
      "('in', 'the', 'previous')\n",
      "('the', 'previous', 'sections')\n",
      "('previous', 'sections', 'lambda')\n",
      "('sections', 'lambda', 'values')\n",
      "('lambda', 'values', 'have')\n",
      "('values', 'have', 'a')\n",
      "('have', 'a', 'large')\n",
      "('a', 'large', 'effect')\n",
      "('large', 'effect', 'on')\n",
      "('effect', 'on', 'coefficients')\n",
      "('on', 'coefficients', 'so')\n",
      "('coefficients', 'so', 'now')\n",
      "('so', 'now', 'we')\n",
      "('now', 'we', 'will')\n",
      "('we', 'will', 'compute')\n",
      "('will', 'compute', 'and')\n",
      "('compute', 'and', 'chose')\n",
      "('and', 'chose', 'a')\n",
      "('chose', 'a', 'suitable')\n",
      "('a', 'suitable', 'one')\n",
      "('suitable', 'one', 'Here')\n",
      "('one', 'Here', 'we')\n",
      "('Here', 'we', 'perform')\n",
      "('we', 'perform', 'a')\n",
      "('perform', 'a', 'cross')\n",
      "('a', 'cross', 'validation')\n",
      "('cross', 'validation', 'and')\n",
      "('validation', 'and', 'take')\n",
      "('and', 'take', 'a')\n",
      "('take', 'a', 'peek')\n",
      "('a', 'peek', 'at')\n",
      "('peek', 'at', 'the')\n",
      "('at', 'the', 'lambda')\n",
      "('the', 'lambda', 'value')\n",
      "('lambda', 'value', 'corresponding')\n",
      "('value', 'corresponding', 'to')\n",
      "('corresponding', 'to', 'the')\n",
      "('to', 'the', 'lowest')\n",
      "('the', 'lowest', 'prediction')\n",
      "('lowest', 'prediction', 'error')\n",
      "('prediction', 'error', 'before')\n",
      "('error', 'before', 'fitting')\n",
      "('before', 'fitting', 'the')\n",
      "('fitting', 'the', 'data')\n",
      "('the', 'data', 'to')\n",
      "('data', 'to', 'the')\n",
      "('to', 'the', 'model')\n",
      "('the', 'model', 'and')\n",
      "('model', 'and', 'viewing')\n",
      "('and', 'viewing', 'the')\n",
      "('viewing', 'the', 'coefficients')\n",
      "('the', 'coefficients', 'We')\n",
      "('coefficients', 'We', 'can')\n",
      "('We', 'can', 'see')\n",
      "('can', 'see', 'here')\n",
      "('see', 'here', 'that')\n",
      "('here', 'that', 'certain')\n",
      "('that', 'certain', 'coefficients')\n",
      "('certain', 'coefficients', 'have')\n",
      "('coefficients', 'have', 'been')\n",
      "('have', 'been', 'pushed')\n",
      "('been', 'pushed', 'towards')\n",
      "('pushed', 'towards', 'zero')\n",
      "('towards', 'zero', 'and')\n",
      "('zero', 'and', 'minimized')\n",
      "('and', 'minimized', 'while')\n",
      "('minimized', 'while', 'RM')\n",
      "('while', 'RM', 'number')\n",
      "('RM', 'number', 'of')\n",
      "('number', 'of', 'rooms')\n",
      "('of', 'rooms', 'has')\n",
      "('rooms', 'has', 'a')\n",
      "('has', 'a', 'significantly')\n",
      "('a', 'significantly', 'higher')\n",
      "('significantly', 'higher', 'weight')\n",
      "('higher', 'weight', 'than')\n",
      "('weight', 'than', 'the')\n",
      "('than', 'the', 'rest')\n",
      "('the', 'rest', 'Performing')\n",
      "('rest', 'Performing', 'Lasso')\n",
      "('Performing', 'Lasso', 'regression')\n",
      "('Lasso', 'regression', 'The')\n",
      "('regression', 'The', 'steps')\n",
      "('The', 'steps', 'will')\n",
      "('steps', 'will', 'be')\n",
      "('will', 'be', 'identical')\n",
      "('be', 'identical', 'to')\n",
      "('identical', 'to', 'what')\n",
      "('to', 'what', 'we')\n",
      "('what', 'we', 'have')\n",
      "('we', 'have', 'done')\n",
      "('have', 'done', 'for')\n",
      "('done', 'for', 'ridge')\n",
      "('for', 'ridge', 'regression')\n",
      "('ridge', 'regression', 'The')\n",
      "('regression', 'The', 'value')\n",
      "('The', 'value', 'of')\n",
      "('value', 'of', 'alpha')\n",
      "('of', 'alpha', 'is')\n",
      "('alpha', 'is', 'the')\n",
      "('is', 'the', 'only')\n",
      "('the', 'only', 'change')\n",
      "('only', 'change', 'here')\n",
      "('change', 'here', 'remember')\n",
      "('here', 'remember', 'qq')\n",
      "('remember', 'qq', '1')\n",
      "('qq', '1', 'denotes')\n",
      "('1', 'denotes', 'lasso')\n",
      "('denotes', 'lasso', 'Performing')\n",
      "('lasso', 'Performing', 'Elastic')\n",
      "('Performing', 'Elastic', 'Net')\n",
      "('Elastic', 'Net', 'regression')\n",
      "('Net', 'regression', 'Performing')\n",
      "('regression', 'Performing', 'Elastic')\n",
      "('Performing', 'Elastic', 'Net')\n",
      "('Elastic', 'Net', 'requires')\n",
      "('Net', 'requires', 'us')\n",
      "('requires', 'us', 'to')\n",
      "('us', 'to', 'tune')\n",
      "('to', 'tune', 'parameters')\n",
      "('tune', 'parameters', 'to')\n",
      "('parameters', 'to', 'identify')\n",
      "('to', 'identify', 'the')\n",
      "('identify', 'the', 'best')\n",
      "('the', 'best', 'alpha')\n",
      "('best', 'alpha', 'and')\n",
      "('alpha', 'and', 'lambda')\n",
      "('and', 'lambda', 'values')\n",
      "('lambda', 'values', 'and')\n",
      "('values', 'and', 'for')\n",
      "('and', 'for', 'this')\n",
      "('for', 'this', 'we')\n",
      "('this', 'we', 'need')\n",
      "('we', 'need', 'to')\n",
      "('need', 'to', 'use')\n",
      "('to', 'use', 'the')\n",
      "('use', 'the', 'caret')\n",
      "('the', 'caret', 'package')\n",
      "('caret', 'package', 'We')\n",
      "('package', 'We', 'will')\n",
      "('We', 'will', 'tune')\n",
      "('will', 'tune', 'the')\n",
      "('tune', 'the', 'model')\n",
      "('the', 'model', 'by')\n",
      "('model', 'by', 'iterating')\n",
      "('by', 'iterating', 'over')\n",
      "('iterating', 'over', 'a')\n",
      "('over', 'a', 'number')\n",
      "('a', 'number', 'of')\n",
      "('number', 'of', 'alpha')\n",
      "('of', 'alpha', 'and')\n",
      "('alpha', 'and', 'lambda')\n",
      "('and', 'lambda', 'pairs')\n",
      "('lambda', 'pairs', 'and')\n",
      "('pairs', 'and', 'we')\n",
      "('and', 'we', 'can')\n",
      "('we', 'can', 'see')\n",
      "('can', 'see', 'which')\n",
      "('see', 'which', 'pair')\n",
      "('which', 'pair', 'has')\n",
      "('pair', 'has', 'the')\n",
      "('has', 'the', 'lowest')\n",
      "('the', 'lowest', 'associated')\n",
      "('lowest', 'associated', 'error')\n",
      "('associated', 'error', 'We')\n",
      "('error', 'We', 'can')\n",
      "('We', 'can', 'see')\n",
      "('can', 'see', 'that')\n",
      "('see', 'that', 'the')\n",
      "('that', 'the', 'R')\n",
      "('the', 'R', 'mean-squared')\n",
      "('R', 'mean-squared', 'values')\n",
      "('mean-squared', 'values', 'using')\n",
      "('values', 'using', 'all')\n",
      "('using', 'all', 'three')\n",
      "('all', 'three', 'models')\n",
      "('three', 'models', 'were')\n",
      "('models', 'were', 'very')\n",
      "('were', 'very', 'close')\n",
      "('very', 'close', 'to')\n",
      "('close', 'to', 'each')\n",
      "('to', 'each', 'other')\n",
      "('each', 'other', 'but')\n",
      "('other', 'but', 'both')\n",
      "('but', 'both', 'did')\n",
      "('both', 'did', 'marginally')\n",
      "('did', 'marginally', 'perform')\n",
      "('marginally', 'perform', 'better')\n",
      "('perform', 'better', 'than')\n",
      "('better', 'than', 'ridge')\n",
      "('than', 'ridge', 'regression')\n",
      "('ridge', 'regression', 'Lasso')\n",
      "('regression', 'Lasso', 'having')\n",
      "('Lasso', 'having', 'done')\n",
      "('having', 'done', 'best')\n",
      "('done', 'best', 'Lasso')\n",
      "('best', 'Lasso', 'regression')\n",
      "('Lasso', 'regression', 'also')\n",
      "('regression', 'also', 'showed')\n",
      "('also', 'showed', 'the')\n",
      "('showed', 'the', 'highest')\n",
      "('the', 'highest', 'R²')\n",
      "('highest', 'R²', 'value')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trigrams = ngrams(wtokens,3)\n",
    "for i in trigrams:\n",
    "    print(i)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trigrams2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-31102c5a26c7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mruns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mmost_trigrams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrigrams2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mmost_trigrams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmost_trigrams\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mruns\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'trigrams2' is not defined"
     ]
    }
   ],
   "source": [
    "runs = 0\n",
    "most_trigrams = ()\n",
    "for t in trigrams2:\n",
    "    most_trigrams = most_trigrams + (t,)\n",
    "    runs += 1\n",
    "    if runs >= 10:\n",
    "        break\n",
    "\n",
    "for g in most_trigrams:\n",
    "    print(g)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('we', 'need', 'to'), 3)\n",
      "(('Performing', 'Elastic', 'Net'), 2)\n",
      "(('We', 'can', 'see'), 2)\n",
      "(('a', 'lambda', 'value'), 2)\n",
      "(('a', 'number', 'of'), 2)\n",
      "(('alpha', 'and', 'lambda'), 2)\n",
      "(('and', 'L2', 'regularization'), 2)\n",
      "(('equal', 'to', 'the'), 2)\n",
      "(('find', 'the', 'optimal'), 2)\n",
      "(('is', 'equal', 'to'), 2)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "temp = nltk.collocations.TrigramCollocationFinder.from_words(wtokens)\n",
    "# Sort trigrams in the frequency they appear\n",
    "trigrams2 = sorted(temp.ngram_fd.items(), key=lambda t: (-t[1], t[0]))\n",
    "\n",
    "# Extract the first top 10 trigrams\n",
    "runs = 0\n",
    "most_trigrams = ()\n",
    "for t in trigrams2:\n",
    "    most_trigrams = most_trigrams + (t,)\n",
    "    runs += 1\n",
    "    if runs >= 10:\n",
    "        break\n",
    "\n",
    "for g in most_trigrams:\n",
    "    print(g)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "First we need to understand the basics of regression and what parameters of the equation are changed when using a specific model. But the data we need to define and analyze is not always so easy to characterize with the base OLS model. Performing Elastic Net requires us to tune parameters to identify the best alpha and lambda values and for this we need to use the caret package.\n",
      "\n",
      "2\n",
      "Performing Elastic Net regression. Performing Elastic Net requires us to tune parameters to identify the best alpha and lambda values and for this we need to use the caret package.\n",
      "\n",
      "3\n",
      "We can see here that certain coefficients have been pushed towards zero and minimized while RM (number of rooms) has a significantly higher weight than the rest. We can see that the R mean-squared values using all three models were very close to each other, but both did marginally perform better than ridge regression (Lasso having done best).\n",
      "\n",
      "4\n",
      "Similar to ridge regression, a lambda value of zero spits out the basic OLS equation, however given a suitable lambda value lasso regression can drive some coefficients to zero. A third commonly used model of regression is the Elastic Net which incorporates penalties from both L1 and L2 regularization:\n",
      "In addition to setting and choosing a lambda value elastic net also allows us to tune the alpha parameter where qq = 0 corresponds to ridge and qq = 1 to lasso.\n",
      "\n",
      "5\n",
      "The gradient descent algorithm is used to find the optimal cost function by going over a number of iterations. We will tune the model by iterating over a number of alpha and lambda pairs and we can see which pair has the lowest associated error.\n",
      "\n",
      "6\n",
      "Performing Elastic Net requires us to tune parameters to identify the best alpha and lambda values and for this we need to use the caret package. We will tune the model by iterating over a number of alpha and lambda pairs and we can see which pair has the lowest associated error.\n",
      "\n",
      "7\n",
      "These are known as L1 regularization (Lasso regression) and L2 regularization (ridge regression). A third commonly used model of regression is the Elastic Net which incorporates penalties from both L1 and L2 regularization:\n",
      "In addition to setting and choosing a lambda value elastic net also allows us to tune the alpha parameter where qq = 0 corresponds to ridge and qq = 1 to lasso.\n",
      "\n",
      "8\n",
      "The L2 term is equal to the square of the magnitude of the coefficients. The penalty applied for L2 is equal to the absolute value of the magnitude of the coefficients:\n",
      "L1 regularization penalty term.\n",
      "\n",
      "9\n",
      "The equation for this model is referred to as the cost function and is a way to find the optimal error by minimizing and measuring it. The gradient descent algorithm is used to find the optimal cost function by going over a number of iterations.\n",
      "\n",
      "10\n",
      "The L2 term is equal to the square of the magnitude of the coefficients. The penalty applied for L2 is equal to the absolute value of the magnitude of the coefficients:\n",
      "L1 regularization penalty term.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stokens = nltk.sent_tokenize(text)\n",
    "most_trigrams2 = ()\n",
    "for i,u in most_trigrams:\n",
    "    most_trigrams2 = most_trigrams2 + (i,)\n",
    "tristrings = []\n",
    "temporary = list(most_trigrams2)\n",
    "for d in range(0,10):\n",
    "    tempstring = ' '.join(temporary[d])\n",
    "    tristrings.append(tempstring)\n",
    "Sentlist = list(stokens)\n",
    "Sentences = []\n",
    "temps = []\n",
    "\n",
    "for k in range(len(tristrings)):\n",
    "    temps2 = ''\n",
    "    temps = []\n",
    "    for i in range(len(Sentlist)):\n",
    "        # Check to see if trigram string is in the Sentence string\n",
    "        if tristrings[k] in Sentlist[i]:\n",
    "            # Append Sentences to a list\n",
    "            temps.append(Sentlist[i])\n",
    "    temps2 = ' '.join(temps)\n",
    "    Sentences.append(temps2)\n",
    "\n",
    "# Part h. Print the concatenated result\n",
    "q = 1\n",
    "for i in Sentences:\n",
    "    print(q)\n",
    "    print(i)\n",
    "    print()\n",
    "    q += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
